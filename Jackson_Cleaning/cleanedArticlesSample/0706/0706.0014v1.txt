 The determinant computation is one of the core problems in linear algebra. To our knowledge the problem of the exact computation of the determi nant of a rational matrix i.e a matrix with ratio nal entries has not yet been widely studied. Ingeneral exact algorithms can be used everywhere where large precision is required. For example the determinant can be too close to or and thus cannot be computed by oating point precision al gorithms. In the case of illconditioned matrices symbolic methods can be preferred as rounding er rors can spoil the computation. It can also be in teresting to compare the use of decimal and contin ued fractions approximations of the entries of real valued matrices. Continued fractions are the best approximants with small denominators see Ch. . In this paper we will try to face the question of how ecient an exact determinant computation can be in both cases. LinBox library implements exact algorithms for the determinant computation in the case of mod ular and integer domains. By using fast modular routines it can oer solutions an order of mag nitude faster than other existing implementations . We apply these procedures to the computation of the determinant of a rational matrix. Rational eld arithmetics is implemented in GMP and Givaro libraries. In general rational numbers are dicult to treat from the exact com putation point of view. Mainly the size of the nu merator and denominator can increase very quickly with every addition and multiplication. When we add or multiply two fractions with numerators and denominators bounded by M the numerator and denominator of the result are bounded by OM. Moreover one addition requires and one mul tiplication requires integer products as well as a gcd computation. Therefore the cost of an ex act matrixvector or matrixmatrix product can be prohibitive in practice. This prohibits the use of the rational eld Qin most exact linear algebra algorithms which rely on matrixmatrix or matrix vector products.However the cost of computing a modular image of a rational numbera b where abare of moderate size should be comparable with the cost of com puting a modular image of a large integer number. This allows us to compute a modular image of a ra tional matrix at a reasonable cost and thus enables us to use modular procedures. To compute the determinant of a rational matrix Aaij bij bij the problem of matrix storage has to be considered. First we can store the entries ofAas rational numbers. Furthermore one could store the common denominator DA of all entries ofAand an integer matrix Agiven by the formula A DAA. This approach can be useful in the case when the entries of Aare decimal fractions and DA can be set to a power of . But if we only assume that the values aij bijare less than M bothDA andbardblAbardblare bounded by OMn. Still we may store the common denominator for each row column separately. Then the integer vectors Ai are given by the equation Ai DiAi where Ai is the matrix row column and Diis the common denominator of its entries. Vectors Aiform matrix A the norm of which is bounded by OMn. The product Digives a more accurate approximation of the denominator DdetA than DAn. The purpose of this paper is to propose the strate gies to compute the denominator of a rational ma trix. All approaches are based on modular com putation. Depending on the matrix storage deter minant andor matrix preconditioning is proposed. The resulting algorithms can use the rational re construction Ch. andor existing integer de terminant algorithms. The rest of the paper is organized as follows. In sec tion we give a short description of the existing al gorithms for the rational reconstruction and the in teger determinant problem. In section we present the main result i.e. two preconditioning strategies and four new algorithms to compute the rational determinant. The cost of the algorithms can be described in terms of the number of modular im ages of Aand modular determinant computations needed. Depending on the strategy the cost of the rational reconstruction or padic lifting is taken into account. In section we discuss the cost of com puting a modular image of a matrix and the overall cost of the algorithms. In section we present the experimental results and discuss the best choice of the strategy in practice. We conclude the paper by proposing some mixed solutions in section .. EXISTING ALGORITHMS The aim of this section is to introduce the algo rithms that will be used later in section . In sub section . we give a short description of the ratio nal reconstruction procedure. On the example of p adic system solving we present the application of this procedure to the computation of a rational solution. We show how to change the procedure in the case of early terminated reconstruction and give the complexity estimation in this case. Then in subsection . we present the classical CRA al gorithm for the determinant and its modications by and . . Rationalreconstructionanditsap plication A modular image of a rational numbera bmodM can be computed by taking the modular images of aandband applying the modular division. This fact can be written as a bumodMabumodM. It should be noticed is that the opposite procedure can also be performed. One can reconstruct the fractiona bwhere gcd ab b from it mod ular image u. The solution is usually not unique but when we additionally require that aN bM N then there exists at most one solution see Ch.. The solution to the rational reconstruction prob lem can be computed by applying the extended Euclidean algorithm EEA which searches for the gcd of Mandu. The procedure RatrecabuM N D takes as the input modulus MuZand the bounds NandD and returns a fractiona b umodMsuch that a N b D or FAIL if no such solution exists. The worst case complexity ofRatrec is thus the same as for the EEA algo rithm i.e. O logM for the classical algorithm andOlogMloglog M for the fast Euclidean algorithm see Ch.. We will use the nota tion EEA M for the complexity of the Extended Euclidean Algorithm with entries bounded by M. In many application the cost of rational recon struction is usually small compared with the cost of computing uandM. The general scheme is to re cursively compute uk Mk where Mkpppk orMkpkuntilMkNDand then to apply the rational reconstruction. The complexity of the pro cedure depends on the number kof steps which can be quite large Reducing the number of steps can be the easiest way to enhance the performance of thealgorithm. This can be seen on the example of the Dixon al gorithm to solve a linear system Axbof in teger equations. Let N D be the bound for the numerator and denominator of x. In the classi cal approach we compute the padic approxima tion in k logN log D steps and then reconstruct the result which gives the complex ityO mlogm log bardblAbardbl when we use the bound of Hadamard for D Nand assume bO. See for a detailed complexity study. In fact the number of entries in xwhich we need to reconstruct can often be reduced see . One should however notice that the bounds Nand Dcan be much bigger than the actual result. The idea is therefore to apply the rational reconstruc tion periodically and check the solution for correct ness. If Mkpkis the modulus in the current step the method of Wang prompts us to setq Mk as the current bound for numerators and the de nominator in Ratrec . The algorithm is guaranteed to return the result if Mkmax Nx Dx where NxDx are the values of the numera tor and the denominator. In the opposite case Ratrec ab u M kq Mk q Mk should fail with large probability. If we apply Wangs idea to the padic lifting we can reduce the number of steps to k logpmax NxDx and the complexity be comes O mmklogmbardblAbardbl Current work on this eld focus on further reducing the number of steps in the case when NxDx orDx Nx. A purely heuristic idea is to use the boundsq Mk N Dq Mk D Ninstead ofq Mk . For other ap proaches see . . Integer Determinant Algorithms For an integer matrix Aone has several alterna tives to compute the determinant. The classical ap proach is to use Chinese Remaindering Algorithm CRA to reconstruct the value from suciently many modular images. The modular determinant is computed by LU factorization in the time On where nis the matrix dimension.Each step of the algorithm consist of computation mod piand a re construction of the determinant mod ppiby the Chinese Remaindering Theorem. The computation is stopped when the early termination ET con dition is fullled i.e. the reconstructed result rests the same for several iterations. The algorithm is Monte Carlo type where the probability of success is controlled by the number of repetitions. See for a detailed description. A mixture of CRA loop and Dixon padic lifting is used to compute the integer determinant in and in the hybrid algorithm of . The principle is to reduce the value reconstructed by CRA algorithm by computing a large fraction of the determinant. By solving several linear systems we can compute some largest invariant factors sm . . . s mi. Their product is potentially a large part of the determi nant. An early terminated CRA loop which recon structs det Amodpp piusually requires only a few modular determinant computations. In formally the algorithm can be described as follows. . For i to kdo a Solve Axibiby Dixon padic lifting to ndsm . . . s mi bsm smi c Run CRA for several iterations to deter mine det A d if ET break . Run another determinant algorithm to get the result Here kshould not exceed the expected number of invariant factors which is Op logn see . The expected complexity of the hybrid determi nant algorithm for random dense matrices is O nlog.nbardblAbardbl . In the worst case step we can choose between the CRA algorithm and the al gorithms of . In fact in the expected case we do not need to run this step. The experi ment proved that thanks the adaptive solutions this algorithm performs better than other implementa tion for a larger group of matrices. . RATIONAL DETERMINANT AL GORITHMS The algorithms to compute the rational determi nant are based on the ideas described in section . We present four main strategies to compute the rational determinant. They all use CRA which al lows us to compute the determinant of the matrix modulo a product ppkof primes. Then the rst variant uses the rational reconstruction to ob tain the rational result. In order to make use of Early Termination condition we have to precondi tion the determinant to obtain its integer multipli cation. Preconditioning of the matrix allows us to use the integers determinant algorithms. The ap plication of two determinant algorithms is studiedhere. The common requirements for all algorithm are shown in .. The algorithms are Monte Carlo type due to the early termination used. Requirements . Require A anmmrational matrix Require Dii . . . m the common denomina tor of the entries of the ith row column Require N D the bounds for the numerator and the denominator of det ADDi Require A set Pof random primes Require Ratrec ab u M N D a procedure which reconstructsa bumodM a N b D or returns FAIL. Ensure detA the determinant of the matrix. The eectiveness of our methods depends heavily on the number of modular determinants computed and thus on the bound NandDfor the numerator and the denominator of the determinant. One can compute Das the product of lcm of all denomina tors in a row or a column. Then Ncan be com puted as DH where His the Hadamard bound for matrix A. One should notice that the bounds can be largely overestimated. Thus we proposed outputdependant approach which allows us to re duce the number of iteration. The rst idea is to employ the CRA scheme and compute the determinant for the modular images of a rational matrix. In the case when the determi nant is rational early termination condition never holds. Instead we have to compute the bounds DandNfor the denominator and numerator of the determinant. As soon as the product of primes Mppkovercomes NDwe can apply ratio nal reconstruction and reconstruct the determinant from the modular image. We can also use an output dependent rational reconstruction as described in section .. This strategy is presented as algorithm RatLU. An early termination in the rational case would required applying the rational reconstruction from time to time with the bounds NDq Mk and wait for the result to reoccur. This leads to so lution when M maxn d where n dare the numerator and denominator of the determinant. The second method can use the denominator bound D to make the CRA loop look for an integer value. Again we compute the modular image of a ratio nal matrix Abut this time we call CRA to look for DdetA which is integer. Now the classic ET condition can be used and the result is obtained as soon as M nD d. The eectiveness of this methodAlgorithm . RatLU i k n d M u repeat i Get pifromP Compute AiAmodpi Compute ui det Ai Reconstruct u det Amod Mpiusing M u u i piMMpi ifikthen s Ratrec n d u Mq M q M k ifsneationslash FAIL then return n dend if end if until M ND status Ratrec n d u M N D ifstatus neationslash FAIL then return n dend if depends therefore on the exactness of denominator bound D. Experimental results show that it is suf cient in practice see sec. table . This strategy is presented as algorithm PrecDetLU. Algorithm . PrecDetLU i M u repeat iGetpifromP Compute AiAmodpi Compute uiDdetAi reconstruct uDdetAmod Mpiusing M u u i piMMpi ifET holds then returnu gcduDD gcduD end if until M ND returnu gcduDD gcduD The last two strategies require an integer matrix A which can be obtained by preconditioning the ra tional matrix A. In order to obtain an integer ma trix the easiest way would be to take matrix A DAA where DA is the common denominator of all entries. In the general case where the entries ofAare fractionsaij bijwith numerator and denom inator bounded by bardblAbardbl this is not the best choice as the size of DA can be as large as ObardblAbardblm. This causes log bardblAbardbl to be Om. Moreover the denominator approximation is DAmin this case which is Om in size. We have already dened a tighter bound for the denominator of det A by Di which is Om in size. Now if we want to use the integer matrix Athen we can precondi tionAby taking AAdiagDi where Diare the common denominators of the rows or A diagDiA where Diare the common denominators of the columns. For the preconditioned ma trixAall integer determinant algorithms can be applied. In particular the hybrid determinant algo rithm of can be used. The drawback of this ap proach is the size of the coecients of Acompared toA see section table . This forced us to use early terminated rational reconstruction for system solving in the Dixon padic lifting algorithm. The strategies that use the CRA loop or the hybrid algo rithm are presented as algorithms PrecMatLU and PrecMatDixon respectively. Algorithm . PrecMatLU i M u Compute AAdiagDi or diag DiA repeat Get pifromP Compute AiAmodpi Compute ui det Ai reconstruct u det Amod Mpiusing M u u i piMMpi ifET holds then returnu gcduDD gcduD end if until M ND returnu gcduDD gcduD Algorithm . PrecMatDixon Compute AAdiagDi or diag DiA Compute u det A by HybridDet returnu gcduDD gcduD . COMPLEXITY ANALYSIS In this section we study the complexity of the al gorithms presented in section . In subsection . we present the analysis of the general case where we assume that the entries of the matrix are frac tions with numerators and denominators bounded bybardblAbardbl. Then in subsection . we will focus on two special cases i.e. matrices of decimal fractions and Hilbert matrices. The complexity of the strategies described in sec tion depends on the number of iterations required by the while loop of CRA. Then depending on the strategy we have to include the cost of computing the homomorphic image of the matrix the cost of the rational reconstruction or the cost of padic lift ing. If we use the early termination condition the number of steps required for the computation of detA depends on the values m the size of the matrix n d the real values of the numerator and denominator of det A and D the bound for the denominator. The cost of homomorphic imagingdepends on the maximum norm of the matrix i.e. bardblAbardbl max bardblaijbardbl bijandbardblAbardbl. . General case We start this section by the analysis of the ratio nal homomorphic imaging schemes. We have the following lemma. Lemma ..Letpbe a wordsize prime. Then the complexity of computing the modular image at p for a rational matrix AisOmlogbardblAbardblEEA p word operations. Proof. For a matrix without a pattern we com pute an image for all mentries. For a rational fraction the cost is OlogbardblAbardbl for the computa tion of the modular image of the numerator and de nominator and EEA p Ologp loglog p for the modular inverse computation by fast extended Euclidean algorithm. Therefore for a wordsize bardblAbardbl the cost of computing the image is O yet impor tant due to the constant for computing the inverse of an element mod p. For the integer case the cost is log bardblAbardbl. We can notice that log bardblAbardbl can be OmlogbardblAbardbl in the worst case so the complexity of homomorphic imaging in terms of misOm for the rational andOm in the integer case. But if bardblAbardbl pthe cost of imaging for one element is . Thus if both bardblAbardblandbardblAbardblare less than p the complexity of the homomorphic imaging becomes mEEA p for the rational and mfor the integer case. In this case it is better to use integer imaging. On the other hand if matrix Ais structured for example it is Hankeltype we have the complexity mEEA p for rational imaging. Due to the preconditioning we loose the structure pattern for Aand the complex ity of integer imaging rests without change. Finally we notice that for sparse matrices with elements we can take instead of min the complexity for mula. Putting it together we have the following theorem. Theorem ..The worst case complexities of the strategies for computing the determinant of a ratio nal matrix Aof size mare .O kmlogbardblAbardbl m O k k for RatLU where Ohides some logkfactors.O logD dnmlogbardblAbardbl m for PrecDetLU .O logD dnmlogbardblAbardbl m for PrecMatLU .Oxmlogmlog bardblAbardblmx OlogD dn sm mlogbardblAbardblmfor PrecMatDixon where smsmAandxmlogmbardblAbardblbardblbbardblis the size of solution to Axb. Here Ais equal to AdiagDias in section nd are the numerator and denominator of detAand kOmaxlog nlogd. Proof. The complexities can be obtained by a careful examination of the number of CRA steps. The result for alg. RatLU takes into account the cost of the rational reconstruction which is per formed at most O k times. In alg. PrecMat Dixon we introduce xto estimate the cost of early terminated padic lifting. The size of xcan gen erally vary depending on the choice of bbut is OmlogmbardblAbardblbardblbbardbl in the worst case. To further evaluate the worst case complexity of alg. PrecMat Dixon we assumed that HybridDet continues to use CRA loop in the worst case. Thus the number of iterations OlogD dn sm and the complexity. Special care should be taken if we consider the use of alg. PrecMatDixon. As bardblAbardblcan potentially be Om in size and with a pessimistic bound on x its worst case complexity can be Ologm which is worse than for the CRA computation. Nev ertheless the gain of computing smcan be impor tant as it is the case in the HybridDet algorithm see . . Complexity inthe specialcases By the precedent remarks it should be visible that the analysis of the strategies should be divided into two main cases. One would consist of the matri ces whose entries are given by decimal fraction or more generally where the common denomina tor of all entries the common denominator of the rows and the norm of Aare of the same order i.e. DA ODi ObardblAbardbl. In the other case ma trix entries are given as fractions with dierent de nominators. We will study the complexity of the algorithms on the example of Hilbert matrices. In the case of matrices of decimal fractions let us further assume that bardblAbardblisO. This would be the case of numerous illconditioned matrices emergingfrom dierent applications in science and engineer ing. In order to better describe the dierences be tween the algorithms we include the cost of EEA when it is relevant. The theorem is a straightfor ward consequence of theorem .. Theorem ..The complexities of the strategies in the case when bardblAbardblObardblAbardbl Oare .O kmEEA p mk k for alg. RatLU .O logD dnmEEA p m for alg. PrecDetLU .O logD dnmm for alg. PrecMatLU .O xmlogm mx logD dn smmm for alg. PrecMatDixon. where k xare as in theorem .. The analysis suggests that the algorithm PrecMatLU should be better than PrecDetLU see . for the homo morphic image complexity. The performance anal ysis in section conrms this observation. Further more as long as the Smith form of Ais simple we encourage the use of strategy PrecMatDixon. In particular we can establish an equivalence between matrices Aof random decimal fractions with edec imal places taken randomly an uniformly from the interval and matrices AbardblAbardble. This allows us to use the expected complexity of the hy brid algorithms of as the expected complexity of the rational determinant computation by alg. PrecMatDixon. Also the preconditioning should be used instead of strategy RatLU. For more de tails see section . The other group consists of matrices with ratio nal entries given by fractions with very dierent denominators. As a model case we can consider Hilbert matrices. Hilbert matrices are the matrices of the form Hm ijij..m. They are bench marks examples for many numerical methods. The formula for the determinant of a Hilbert matrix is well known and is given by the equation detHm m kk k k . Theorem ..The complexities for rational de terminant strategies in the case of Hilbert matrices are.O mlogmmmp logm for alg. RatLU .O mlogm for alg. PrecDetLU .O m logm for alg. PrecMatLU .Osmmlogm mlogmfor alg. Prec MatDixon. Proof. One should notice that log detHm is Omlogm. The size of entries of Hmis logbardblHmbardbl Ologm and log bardblHmbardbl Omlogm. In the case of Hilbert matrices algorithm PrecDetLU has the best time complexity and also performed best in the experiments see section . Since the numerator is equal to we only have to recover the size of the overapproximation. Experimental results show that its size is equal to about of the denominator size. Therefore alg. PrecDetLU PrecMatLU perform about times less iterations than RatLU. As for the algorithm PrecMatDixon the study of the Smith form of Hmhas revealed that it is quite complex with about mnontrivial fac tors and the size log smHm equal Om. Thus it is not worth computing PrecMatDixon due to the high cost of the algorithm and poor gain. . PERFORMANCECOMPARISON In this section we present the experimental results for four strategies from section . We have tested the performance of four strategies on three matrix sets random illconditioned and Hilbert matrices. We generated the random matrices using Matlab procedure rand. The entries of the matrices are decimal fractions with decimal places chosen ran domly from the interval . The determinant of the resulting matrices is large in the absolute value. The result of the numerical procedure of Matlab is . Illconditioned matrices have been chosen from the Matrix Market HarwellBoeing collection. We chose three sets Grenoble Astroph and Bcsstruc. Grenoble set represents the results of the simula tion of computer systems. The sizes of the matri ces varies from to and the condition num bers range from .in the case of the smallest matrix to .for the biggest. The decimal precision of the entries depends on the matrix and ranges from to decimal places. The determi nants are close to . For these matrices Matlab procedure detcomputes the result correctly up tothe th decimal place. Since matrix entries seem to be represented as rounded expansions of rational numbers we computed the determinant of the ma trices as is and then we took continued fractions approximants of the entries with the same precision as the decimal fractions. Astroph set describes the process of nonlinear ra diative transfer and statistical equilibrium in as trophysics. The condition number is .for the small matrix and .for the one. The result of Matlab computation is. Bcsstruc gives dynamic analyses in struc tural engineering. All matrices are symmetric. The condition number is about for matrices and and for matrix . The result of Matlab computation is . We split the analysis of the performance of the al gorithms in three phases. First we will consider the cost of rationalmodular vs. integermodular imaging and compare it with the results for bardblAbardbl andbardblAbardbl. Then we will take a look on the nu merator and denominator approximations DandN computed by our algorithms. Finally we give the timings for all strategies and compare their perfor mance. As we can see in table the time of computing an integer image can be several times shorter than for the rational image provided that the size of precon ditioned matrix is still small. This is not the case for Hilbert matrices of dimension when the time of rational image computation is better. Fur thermore for structured matrices like Hilbert we can reduce the number of images computed. For a Hankeltype matrix there are only n im ages to compute which makes the cost of imaging negligible. The performance of the algorithms depends on the accuracy of denominator approximation used. For the bound DDi the resulting size of the over approximation is shown in table column . In algorithm PrecMatDixon we additionally approx imate the numerator by computing smA. In this case we are interested in the value AppN smA andD dn smAwhich we compute instead of the nu merator. As we can see in the table the quality of the approximation of the denominator depends on the matrix and ranges from in the case of sparse matrices in the Grenoble set to for Bccstk matrices. For Hilbert matrices the approxi mation is quite ecient the overapproximation is always less than . Table shows that despiteA RatIm IntIm IntImRatIm logbardblAbardbllogbardblAbardbl bccstk . . . bccstk . . . bccstk . . . mmca . . . mccf . . . grenoble . . . grenoble . . . grenoblea . . . grenobleb . . . grenoble . . . grenoble . . . grenoble . . . random . . . random . . . random . . . random . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . Table Comparison of the times in sec onds for homomorphic imaging are given in columns RatIm for rational and IntIm for integer. The ratio of the timings is given in column . Last two columns give the size of entries for Aand A. Matrix size is included in its name. the size of the overapproximation preconditioning allow us to gain enough to beat the naive RatLU al gorithm. If the size of bardblAbardblis small as is the case for sparse matrices we can compute smA at a relatively low cost and eciently approximate the numerator. The timings for all algorithms are shown in table . The results for Hilbert matrices agree with the complexity estimation in Thm. .. Note that alg. PrecMatDixon is usually the best for the matrices from MatrixMarket collection. For the Grenoble set the approximation by contin ued fractions allowed quite well in our opinion to reconstruct the orginal rational matrix connected to the problem. Despite the dierence in proper ties the running times for the decimal and con tinued fractions variants were simmilar. However although the matrices were close in the maximum norm the determinants ratio reached as much as in the case of grenoble. In gure we present the results of the determinant computation for Hilbert matrices. We compare the timings for algorithm RatLU PrecDetLU Prec MatLU PrecMatDixon and the Maple LinearAlge braDeterminant algorithm with methodrational . The best performance is observed for a variant of algorithm PrecDetLU which takes into account theA logdlognlogDdlogDd dlogAppnlogDn dAppN bccstk . bccstk . bccstk . mmca . mccf . grenoble . grenoble . grenoblea . grenobleb . grenoble . grenoble . grenoble . random random random random hilbert . hilbert . hilbert . hilbert . hilbert . hilbert . hilbert . Table The size of the numerator nand de nominator dofdetA the size of the denom inator overapproximation Ddcomputed by PrecDetLU and PrecMatLU the numera tor approximation Appnobtained as smin PrecMatDixon and the size of the part re maining to compute. smdepends on nand the overapproximation Dd. Matrix RatLU PrecDetLU PrecMatLU PrecMatDixon bccstk . . . bccstk . . . . bccstk . . . . mmca . . . . mccf . . . grenoble . . . . grenoble . . . . grenoblea . . . . grenobleb . . . . grenoble . . . . grenoble . . . . grenoble . . . random . . . . random . . . . random . . . . random . . . hilbert . . . . hilbert . . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . hilbert . . . Table Timing comparison for rational determinant strategies. All times in seconds. Best times in bold. Time s nRational determinant computation timings comparison RatLU PrecDetLU PrecDetLUsym PrecMatLU PrecMatDixon Maple Figure Comparison of the timings for the exact computation of the rational de terminant of Hilbert matrices. The results for algorithms RatLU PrecDetLU Prec MatLU and PrecMatDixon implemented in LinBox and Maple Determinant procedure are shown. Algorithm PrecDetLU is used in the classic and symmetric variant which takes into account the Hankel structure of the matrix. All times in seconds. Hankel structure of the matrix. . CONCLUSIONS It this paper we have presented four strategies for exact computation of the determinant of a ratio nal matrix. We have evaluated the performance of these algorithms on several sets of matrices. The performance of the algorithms suggests that there exists a clear division between the matrices given as a rational approximation by decimal fractions of real valued matrices and the matrices with a great diversity of the denominators of the entries. For the rst case matrix preconditioning which leads to a integer matrix is proposed which allows us to use integer determinant algorithms see solution PrecMatDixon. For the second case determinant preconditioning is preferred which does not lead to matrix coecient blowup. In general precon ditioning proved more useful than rational recon struction tools although better early termination methods where the modulus Mis linear in the size of the output nanddcan bring a change see . An adaptive solution should be able to choose the best storage method and homomorphic imaging scheme and work independently of the determinant over approximation. We propose the following solution which incorpo rates the elements of all algorithms. Compute DDiA setN . If logpbardblAbardbl C compute NsmbardblAbardbl see alg. PrecMatDixon . Compute the modular image of the rational matrix Aand integer matrix A determine whether to use PrecDetLU or PrecMatLU based on the timings. . Run the ET CRA loop forD NdetA using PrecDetLU or PrecMatLU. . From time to time check by rational recon struction the early termination condition on detA see RatLU. This algorithm can be further developed to com pute other invariant factors as in alg. PrecMat Dixon if relevant. Notice that the cost of intro ducing solution RatLU to the adaptive algorithm is virtually that of rational reconstruction. Further work can include intertwining algorithms RatLU and PrecDetLU to include the use of less exact determinant preconditioners which potentially are not a multiple of d. The aim would to re duce a factor of the denominator by precondition ing and reconstruct the remaining part by rational reconstruction. The strategy should be eective if the overapproximation caused by precondition ing is reduced but a large fraction of the denomi nator is obtained at the same time. For example DDigcdDi could be considered. Further work can then focus on the implementation of the solution in the case of sparse matrices and on the parallelization of the algorithms. In this paper we have considered the case of dense matrices in the analysis of the complexity of the strategies as well as in the implementation. How ever sparse matrix counterparts of the algorithms can also be used. For the modular determinant computation one could used the algorithm of Wiede mann that computes the determinant by nd ing the characteristic polynomial of the matrix. In alg. PrecMatDixon the sparse solver of can be used. The strategies described in this paper contain ele ments that allow parallelization. This concerns in particular the CRA loop where several iterations can be performed at the same time see . The question of an optimally distributed early termina tion in the case of integer Chinese reconstructionalg. PrecDetLU PrecMatLU PrecMatDixon as well as the rational reconstruction alg. RatLU has not yet been addressed. For a parallel padic lifting for alg. PrecMatDixon see . In this paper we have developed and compared four strategies to compute the rational determinant of a matrix. We have proposed two preconditioning methods that allow us to transfer the problem from rational to integer domain. We believe that the ap proach described in this article can also be applied in other problems of exact computation in ratio nal numbers such as rank computation or system solving. . 