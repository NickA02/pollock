import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer

model = T5ForConditionalGeneration.from_pretrained("t5-large")
tokenizer = T5Tokenizer.from_pretrained("t5-large")

import gradio as gr
import os
import docx2txt


def summarize(text_file):
    file_extension = os.path.splitext(text_file.name)[1]
    if file_extension == ".txt":
        # Load text from a txt file
        with open(text_file.name, "r", encoding="utf-8") as f:
            text = f.read()
    elif file_extension == ".docx":
        # Load text from a Word file
        text = docx2txt.process(text_file.name)
    else:
        raise ValueError(f"Unsupported file type: {file_extension}")
    
    input_ids = tokenizer.encode(text, return_tensors="pt", max_length=512, truncation=True)
    summary_ids = model.generate(input_ids, max_length=150, num_beams=2)
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return text, summary

iface = gr.Interface(
    fn=summarize,
    inputs=gr.inputs.File(label="Upload a txt file or a Word file for the input text"),
    outputs=[gr.outputs.Textbox(label="Original text"), gr.outputs.Textbox(label="Summary")],
    title="Academic Paper Summarization Demo",
    description="Upload a txt file or a Word file for the input text. Get a summary generated by a small T5 model from Hugging Face.",
)

iface.launch()

