{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "from constants import *\n",
    "import string\n",
    "import json\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Article Cleaning\n",
    "\n",
    "Note: the sample cleanedArticles and rawArticles is only the first few article folders & the first 10 valid articles within those folders (I didnt wanna clog the repo but wanted to show the output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the word \"abstract\" appears before the word \"introduction\" in an article\n",
    "def isValidOrder(text: str):\n",
    "    abstractFound = False\n",
    "    for i in range(len(text)):\n",
    "        if not abstractFound and 'abstract' in text[0:i]:\n",
    "            abstractFound = True\n",
    "        if 'introduction' in text[0:i]:\n",
    "            if abstractFound:\n",
    "                return True\n",
    "            return False\n",
    "        # references showing up before \"abstract\" and \"introduction\"\n",
    "        if 'references' in text[0:i]:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(sentence: str):\n",
    "    nlp = spacy.load('en')\n",
    "    nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
    "    doc = nlp(sentence)\n",
    "    detect_language = doc._.language\n",
    "    if detect_language[\"language\"] != 'en':\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading folder: \n",
      "reading folder: 0704\n",
      "reading folder: 0705\n",
      "reading folder: 0706\n",
      "reading folder: 0707\n",
      "reading folder: 0708\n",
      "reading folder: 0709\n",
      "reading folder: 0710\n",
      "reading folder: 0711\n",
      "reading folder: 0712\n",
      "reading folder: 0801\n",
      "reading folder: 0802\n",
      "reading folder: 0803\n",
      "reading folder: 0804\n",
      "reading folder: 0805\n",
      "reading folder: 0806\n",
      "reading folder: 0807\n",
      "reading folder: 0808\n",
      "reading folder: 0809\n",
      "reading folder: 0810\n",
      "reading folder: 0811\n",
      "reading folder: 0812\n",
      "reading folder: 0901\n",
      "reading folder: 0902\n",
      "reading folder: 0903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rootdir = 'articles'\n",
    "validArticles = {}\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    subdir = subdir.replace('\\\\', '')\n",
    "    subdir = subdir.replace(f'{rootdir}', '')\n",
    "    print('reading folder: ' + subdir)\n",
    "    counter = 0\n",
    "    for file in files:\n",
    "        # im only taking the first 10 valid articles for each folder here so I can show input and output on github\n",
    "        if counter == 10:\n",
    "            break\n",
    "        with open(f'{rootdir}/{subdir}/{file}', 'r', encoding='cp1252', errors='ignore') as f:\n",
    "            text = \" \".join(f.readlines())\n",
    "            # only look for articles with \"abstract\", \"introduction\", and \"references\" to make cleaning possible\n",
    "            if 'abstract' in text.lower() and 'introduction' in text.lower() and 'references' in text.lower():\n",
    "                # need to make sure the show up in the right order\n",
    "                if isValidOrder(text.lower()):\n",
    "                    validArticles[file] = text \n",
    "                    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanArticle(text: str):\n",
    "    cleanedText = \"\"\n",
    "    startingIndex = text.lower().find('introduction') + len('introduction')\n",
    "    endingIndex = text.lower().rfind('references')\n",
    "    # only read from the article's introduction section to its references section \n",
    "    text = text[startingIndex:endingIndex]\n",
    "    # get rid of numbers, keep punctuation\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text)\n",
    "    #     The \\( and \\) say we want to target the actual parenthesis.\n",
    "    #     Then the parenthesis around the expression (.*?) say that we want to group what is inside\n",
    "    #     Finally the .*? means that we want any character . and any repetition of that character *?.\n",
    "    text = re.sub(r\"\\((.*?)\\)\", \"\", text)\n",
    "    # remove extra spaces\n",
    "    cleanedText = re.sub(' +', ' ', cleanedText)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "    articleIdentifiers = set()\n",
    "    for articleName in validArticles:\n",
    "        # make a folder path to match the input articles folder structure, if one doesn't already exist\n",
    "        if articleName[0:4] not in articleIdentifiers and not os.path.exists(f'cleanedArticles/{articleName[0:4]}') and not os.pathexists(f'rawArticles/{articleName[0:4]}'):\n",
    "            articleIdentifiers.add(articleName[0:4])\n",
    "            os.mkdir(f'cleanedArticles/{articleName[0:4]}')\n",
    "            os.mkdir(f'rawArticles/{articleName[0:4]}')\n",
    "\n",
    "        # writing raw articles to files (only doing this here because im taking the first 10 valid articles)\n",
    "        text = validArticles[articleName]\n",
    "        text_file = open(f\"rawArticles/{articleName[0:4]}/{articleName}\", \"w\")\n",
    "        text_file.write(text)\n",
    "        text_file.close()\n",
    "        \n",
    "        # writing cleaned articles to files\n",
    "        cleanedText = cleanArticle(text)  \n",
    "        cleaned_text_file = open(f\"cleanedArticles/{articleName[0:4]}/{articleName}\", \"w\", encoding='utf-8')\n",
    "        cleaned_text_file.write(cleanedText)\n",
    "        cleaned_text_file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93c5346a6a3d07125b79d64fc117728ba646bd89aaa0c0db68034b154e209009"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
